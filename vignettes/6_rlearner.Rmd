---
title: "R Learner"
author: "Niklas Rindtorff"
date: "4/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rlearner)
library(randomizr)
```

```{r}
allocation <- read_csv(here("data/allocation.csv"))
load(here("data/crxg_map_imputed.Rdata"))
```


The R-Learner is per default designed to evaluate the CATE of binary treatments. That means, a unit is either treated with a control of an intervention. In our case, we will define a central control arm, Cisplatin, which is commonly used in cases in which no further information about a malignant tumor is available (CUP Syndrome). 

For each treatment, we will train a two-step R-learner and estimate the CATE for the targeted agent vs. Cisplatin. 

We define three functions around the R-learner: 
1. A function that estimates the *w* parameter for weighted allocation
1. A function that will take a matrix of assignments based on therapeutic protocols and will introduce random re-assignments based on the parameters epsilon and gamma. 
1. A function that will take the assignment matrix and train R-learners for every treatment arm
1. A function that will collect the predicted CATEs for each treatment arm and calculate an aggregated performance metric

```{r}
estimate_cross <- function(allocation, 
                       epsilon = 0.05, 
                       ctrl_name = "cisplatin"){
# calculating proportions
df <- allocation %>% 
    gather(assignment, drug, -cosmic_id) %>% 
    filter(drug == 1) %>% 
    count(assignment) %>% 
    mutate(total = sum(n),
           w = n/total,
           type = if_else(assignment == ctrl_name, "ctrl", "treatment")) %>% 
    dplyr::select(-total)

# estimating gamma
g <- df %>% 
  filter(type == "ctrl") %>% 
  .$w # in this case 1- the cummulative w
g <- g*epsilon

# calculating cross_in and cross_over
df %>% filter(type != "ctrl")  %>% 
  mutate(gamma = g) %>%
  mutate(epsilon = epsilon) %>%
  dplyr::select(-type) %>% 
  mutate(cross_in = gamma*w,
         cross_over = epsilon*w) %>%
    return()
}

estimate_cross(allocation) # %>% knitr::kable()
```

```{r}
cross <- estimate_cross(allocation) # %>% knitr::kable()

reassign <- function(var, ctrl = "cisplatin", cross_probs){
  if(var != ctrl){
    # define probs and variables
    probs = c(cross_probs %>% filter(assignment != var) %>% .$cross_over)
    probs = c(1-sum(probs), probs)
    reassignment = c(cross_probs %>% filter(assignment != var) %>%  .$assignment)
    reassignment = c(var, reassignment)
    # return output 
    simple_ra(N = 1, prob_each = probs, conditions= reassignment) %>% 
      as.character() %>% 
      return()
  }
  else if(var == ctrl){
    # define probs and variables
    probs = c(cross_probs %>% filter(assignment != var) %>% .$cross_in)
    probs = c(1-sum(probs), probs)
    reassignment = c(cross_probs %>% filter(assignment != var) %>%  .$assignment)
    reassignment = c(var, reassignment)
    # return output 
    simple_ra(N = 1, prob_each = probs, conditions= reassignment) %>% 
      as.character() %>% 
      return()
  }
  else {"someting is broken"}
}

re_allocation <- allocation %>% 
    gather(assignment, drug, -cosmic_id) %>% 
    filter(drug == 1) %>% 
  dplyr::select(- drug) %>% 
  nest(-cosmic_id) %>%
  mutate(new = purrr::map(data, ~ .x %>% mutate(re_assignment = reassign(assignment, cross_probs = cross)))) %>% 
  unnest(new) %>% 
  dplyr::select(-data) %>% 
  arrange(cosmic_id)
```

After defining a function to perform weighted reassignments, I have to generate result vectors based on a given reassignment. 

```{r}
create_y <- function(allocation_in, response, var, ctrl = "cisplatin"){
  response %>%
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  semi_join(list$df,  by = "cosmic_id") %>%
  dplyr::select(-cosmic_id) %>% 
  
  mutate_all(funs(as.character)) %>%
  mutate_all(funs(as.numeric)) %>%
  as.matrix()

}
```


```{r}
train_rlearner <- function(allocation_in, features, response, var, ctrl = "cisplatin"){
list <- list()

var_q <- sym(var)
ctrl_q <- sym(ctrl)


list$df <- allocation_in %>% 
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  semi_join(response, by = "cosmic_id") %>%
  filter(re_assignment == var |  re_assignment == ctrl) %>% 
  mutate(logical = if_else(re_assignment == ctrl, 0, 1),
         cosmic_id = as.character(cosmic_id))

list$x <- features %>% 
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  semi_join(list$df,  by = "cosmic_id") %>%
  dplyr::select(-cosmic_id) %>%
  mutate_all(funs(as.character)) %>%
  mutate_all(funs(as.numeric)) %>%
  as.matrix()

# getting df into shape

list$df <- list$df %>% 
  semi_join(features %>% 
    mutate(cosmic_id = as.character(cosmic_id)) %>%
    semi_join(list$df,  by = "cosmic_id"), 
  by = "cosmic_id")

list$w <- list$df$logical

list$y <- response %>%
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  left_join(list$df ,.,  by = "cosmic_id") %>%
  dplyr::select_(var, ctrl, "cosmic_id", "re_assignment") %>% 
  mutate(y = if_else(re_assignment == ctrl, !!ctrl_q, !!var_q)) %>% 
  .$y


list$rlasso_fit = rlasso(list$x, list$w, list$y)
list$rlasso_est = predict(list$rlasso_fit, list$x)

list$rboost_fit = rboost(list$x, list$w, list$y)
list$rboost_est = predict(list$rboost_fit, list$x)

return(list)
}

out <- train_rlearner(re_allocation, X, crxg_map_imputed, var = "afatinib", ctrl = "cisplatin")

```



```{r}
set.seed(432)
library(rlearner)
n = 100; p = 10

x = matrix(rnorm(n*p), n, p)
w = rbinom(n, 1, 0.5)
#w = cbind(w, c(1, rep(0, times = n-1)))
y = pmax(x[,1], 0) * w + x[,2] + pmin(x[,3], 0) + rnorm(n)

rlasso_fit = rlasso(x, w, y)
rlasso_est = predict(rlasso_fit, x)

rboost_fit = rboost(x, w, y)
rboost_est = predict(rboost_fit, x)
```


```{r}
library(rlearner)
library(zeallot)

# draw a sample of n observations from a simulation
data = toy_data_simulation(n) 
# data$x is a numeric matrix of covariates (each column having a name)
# data$w is a factor vector where the first level indicates "treatment" and the second "control"
# data$y is a numeric vector of outcomes

# Specify the machine learning models and 
# hyperparameters to be cross-validated over.
# This code specifies the use of elastic net
model_specs = list(
	glmnet = list(
	    tune_grid = expand.grid(
	       alpha=c(0,0.5,1),
	       lambda=exp(seq(-5,2,0.2))),
	    extra_args = list())
)

r_fit = rlearner_cv(data$x, data$w, data$y, tau_model_specs=model_specs)
tau_hat = predict(r_fit, data$x)

print(paste("MSE of tau estimate:", mean((data$tau - tau_hat)^2)))
```

